import csv
import sys
from sklearn.neighbors import LocalOutlierFactor

data = []

# Read data from Hadoop's input
for line in sys.stdin:
    record = line.strip().split(',')
    speed = float(record[1])
    travel_time = float(record[2])
    data.append([speed, travel_time])

# Run the LOF algorithm on the data
lof = LocalOutlierFactor(n_neighbors=5)
lof_scores = lof.fit_predict(data)

# Generate the LOF scores and write results to Hadoop's output
for i, score in enumerate(lof_scores):
    result = f"{data[i][0]},{data[i][1]},{score}"
    print(result)

wget https://archive.apache.org/dist/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz
tar -xzvf hadoop-3.2.2.tar.gz
ls /home/hadoop/hadoop-3.2.2/share/hadoop/tools/lib/hadoop-streaming-3.2.2.jar


#!/bin/bash

# Specify the input file path in HDFS
input_path="/home/hadoop/IST3134/dataset/traffic.csv"

# Specify the output directory path in HDFS
output_path="/home/hadoop/IST3134/pyresults"

# Specify the Python script name
python_script="/home/hadoop/IST3134/lofmp.py"

# Specify the path to Hadoop Streaming JAR
hadoop_streaming_jar="/home/hadoop/hadoop-3.2.2/share/hadoop/tools/lib/hadoop-streaming-3.2.2.jar"
$ start_time=$(date +%s)
# Run the Hadoop Streaming job
hadoop jar $hadoop_streaming_jar \
    -files $python_script \
    -mapper "python3 $python_script" \
    -reducer "cat" \
    -input $input_path \
    -output $output_path
$ end_time=$(date +%s)
$ execution_time=$((end_time - start_time))
$ echo "Execution time: ${execution_time} seconds"
