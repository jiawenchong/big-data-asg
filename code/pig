$ start-all.sh
$ cd IST3134
$ pig -x local -d error

traffic = LOAD '/home/hadoop/IST3134/traffic.csv' USING PigStorage(',') AS (
    ID: int,
    SPEED: float,
    TRAVEL_TIME: int,
    STATUS: int,
    DATA_AS_OF: chararray,
    LINK_ID: chararray,
    OWNER: chararray,
    TRANSCOM_ID: int,
    BOROUGH: chararray, 
    LINK_NAME: chararray
);

-- Filter and project the relevant columns for anomaly detection
grunt> speed_travel_time = FOREACH traffic GENERATE SPEED, TRAVEL_TIME, BOROUGH;

-- Calculate mean for SPEED
grunt> speed_mean = FOREACH (GROUP speed_travel_time ALL) GENERATE AVG(speed_travel_time.SPEED) AS avg_speed;

-- Calculate standard deviation for SPEED
grunt> speed_std = FOREACH (GROUP speed_travel_time ALL) {
    squared_diff = FOREACH speed_travel_time GENERATE (SPEED - speed_mean.avg_speed) * (SPEED - speed_mean.avg_speed) AS diff_squared;
    GENERATE SQRT(AVG(squared_diff.diff_squared)) AS std_speed;
}

-- Calculate mean for TRAVEL_TIME
grunt> travel_time_mean = FOREACH (GROUP speed_travel_time ALL) GENERATE AVG(speed_travel_time.TRAVEL_TIME) AS avg_travel_time;

-- Calculate standard deviation for TRAVEL_TIME
grunt> travel_time_std = FOREACH (GROUP speed_travel_time ALL) {
    squared_diff = FOREACH speed_travel_time GENERATE (TRAVEL_TIME - travel_time_mean.avg_travel_time) * (TRAVEL_TIME - travel_time_mean.avg_travel_time) AS diff_squared;
    GENERATE SQRT(AVG(squared_diff.diff_squared)) AS std_travel_time;
}

-- Cross join the stats relations
grunt> stats_cross = CROSS speed_mean, speed_std, travel_time_mean, travel_time_std;

-- Generate the final stats relation
grunt> stats = FOREACH stats_cross GENERATE
    speed_mean::avg_speed AS avg_speed,
    speed_std::std_speed AS std_speed,
    travel_time_mean::avg_travel_time AS avg_travel_time,
    travel_time_std::std_travel_time AS std_travel_time;

-- Standardize the data (subtract mean and divide by standard deviation)
speed_travel_time_std = FOREACH speed_travel_time GENERATE
    (SPEED - stats.avg_speed) / stats.std_speed AS SPEED_STD,
    (TRAVEL_TIME - stats.avg_travel_time) / stats.std_travel_time AS TRAVEL_TIME_STD,
    BOROUGH;

-- Store the standardized data with borough information
STORE speed_travel_time_std INTO '/home/hadoop/IST3134/preprocessed_data.csv' USING PigStorage(',');

$ cd IST3134/preprocessed_data.csv
$ cat part-m-00000 | less
$ cat part-m-00001 | less

$ pip install scikit-learn
$ nano lof.py
$ start_time=$(date +%s)
$ python3 lof.py
$ end_time=$(date +%s)
$ execution_time=$((end_time - start_time))
$ echo "Execution time: ${execution_time} seconds"

$ cd IST3134/anomalies1.csv
$ cat part-r-00000 | less
$ cat part-r-00001 | less

-- Load the results from the output file
grunt> anomalies = LOAD '/home/hadoop/IST3134/outpig.csv' USING PigStorage(',') AS (data:tuple, lof_score:double);

-- Display the anomalies
grunt> DUMP anomalies;


