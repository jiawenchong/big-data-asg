$ start-all.sh
$ cd IST3134/
$ ls
$ mkdir ~/workspace
$ cp traffic.csv ~/workspace/
$ cd ~
$ hadoop fs -mkdir -p /home/hadoop/IST3134/dataset
$ cd workspace
$ hadoop fs -put traffic.csv /home/hadoop/IST3134/dataset
$ cd ~/workspace/wordcount/src
$ ls
$ cd ~/workspace/lof/src
$ hadoop classpath
$ touch anomalydetection.java
$ javac anomalydetect.java
$ start_time=$(date +%s)
$ hadoop jar lofanomaly.jar LOFAnomalyDetection /user/hadoop/IST3134/dataset/traffic.csv /user/hadoop/IST3134/results
$ end_time=$(date +%s)
$ execution_time=$((end_time - start_time))
$ echo "Execution time: ${execution_time} seconds"
$ jar cf lofanomaly.jar LOFAnomalyDetection$LOFMapper.class LOFAnomalyDetection$LOFReducer.class
$ hadoop fs -ls output
$ hadoop fs -cat output/part-r-00000 | less
$ hadoop fs -rm -r output
